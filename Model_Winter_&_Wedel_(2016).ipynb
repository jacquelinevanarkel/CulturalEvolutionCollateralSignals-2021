{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_Winter & Wedel (2016).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+PB2NOVfAT+6D4ep7or/e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacquelinevanarkel/CulturalEvolutionCollateralSignals-2021/blob/main/Model_Winter_%26_Wedel_(2016).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_zZBw6QKYo4"
      },
      "source": [
        "# Replication of Winter & Wedel (2016) / Wedel (2012)\n",
        "\n",
        "Because we decided to first replicate the study, everything about the collateral signals is left out (but taken into account for the ease of implementation later on). After the resutls are replicated, we adjust the model to introduce a division between word categories: communicative words and metacommunicative words.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_56j5zf_K7YK"
      },
      "source": [
        "## General features\n",
        "\n",
        "- An **agent** consists of a lexicon of $|W|$ word categories (let's start with 4). ~~One word in that set should be singled out as the *continuer* word. In other words, the entire set of word categories $W$ can be further split up into a set of regular \"communicative\" words $C$ and a set of \"metacommunicative\" words $M$, where $W = C \\cup M$ and $C \\cap M = \\varnothing$. Let's start with $|M| = 1$. For the word(s) in the set $M$, additional and/or adapted pressures will apply.~~\n",
        "    - A **word** is represented by a set of exemplars. \n",
        "        - An **exemplar** is represented by a vector that designates a point in an *n*-dimensional space. Let's start with 2 dimensions, and let's have them both range arbitrarily from 0 to 100 (with integer values in between). An example of an exemplar would then be $[15, 25]$ (these individual values in the vector, like 15 and 25, are referred to as \"segments\" by Wedel, 2012).\n",
        "\n",
        "\n",
        "- **Initialisation of an agent:** <span class=\"mark\">Just a randomly generated seed set of exemplars for each word category?</span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzpNaOhse6Cv"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CEl3fbmLAIx"
      },
      "source": [
        "class Agent():\n",
        "\n",
        "  def __init__(self, n_words, n_dimensions, n_exemplars = 100, n_continuers=0, similarity_bias_word=True, similarity_bias_segment=True, noise=True, anti_ambiguity_bias=True):\n",
        "    \n",
        "    self.n_words = n_words\n",
        "    self.n_dimensions = n_dimensions\n",
        "    self.n_exemplars = n_exemplars\n",
        "    self.n_continuers = n_continuers\n",
        "    self.similarity_bias_word = similarity_bias_word\n",
        "    self.similarity_bias_segment = similarity_bias_segment\n",
        "    self.noise = noise\n",
        "    self.anti_ambiguity_bias = anti_ambiguity_bias\n",
        "\n",
        "    # Generate a lexicon as part of the initialisation\n",
        "    self.lexicon, self.com_words, self.meta_com_words = self.generate_lexicon()\n",
        "\n",
        "  # Initialising lexicon\n",
        "  def generate_lexicon(self):\n",
        "\n",
        "    # Create a lexicon consisting of n_words words each in turn consisting of n_exemplars exemplars\n",
        "    lexicon = []\n",
        "    for w in range(self.n_words):\n",
        "      word = []\n",
        "\n",
        "      # Define the mean and the covariance to sample from a multivariate normal distribution to create clustered exemplars for the words\n",
        "      mean = [random.randrange(10, 91) for i in range(self.n_dimensions)]\n",
        "      cov = [[10, 0], [0, 10]]\n",
        "      x, y = np.random.multivariate_normal(mean, cov, self.n_exemplars).T\n",
        "      word.append(list(map(lambda x, y: [x, y], x, y)))\n",
        "      \n",
        "      # Plot every word\n",
        "      plt.scatter(x, y)\n",
        "\n",
        "      # Initialiase all words as 'communicative words' ('C')\n",
        "      lexicon.append([word[0], \"C\"])\n",
        "\n",
        "    # print(lexicon)\n",
        "\n",
        "    # Some plot settings\n",
        "    plt.xlim(0, 100)\n",
        "    plt.ylim(0, 100)\n",
        "    plt.show()\n",
        "\n",
        "    # Split the lexicon into meta communicative words (continuers) and communicative words\n",
        "    if self.n_continuers:\n",
        "      if self.n_continuers > self.n_words:\n",
        "        raise ValueError(\"The number of continuers must be lower than the number of words.\")\n",
        "\n",
        "      # The continuers are randomly chosen out of the lexicon\n",
        "      indices_meta = random.sample(range(self.n_words), k=self.n_continuers)\n",
        "      meta_com_words = []\n",
        "      for index in indices_meta:\n",
        "        lexicon[index][1] = \"M\"\n",
        "        # Create a separate lexicon with the meta communicative words\n",
        "        meta_com_words.append(lexicon[index])\n",
        "\n",
        "      # The words that are not meta communicative words are communicative words\n",
        "      com_words = [word for word in lexicon if word not in meta_com_words]\n",
        "\n",
        "      # print(\"The word categories are split into communicative and metacommunicative words\")\n",
        "      # print(\"New lexicon:\", lexicon)\n",
        "\n",
        "      # print(\"Meta:\", meta_com_words)\n",
        "      # print(\"Com:\", com_words)\n",
        "\n",
        "    # If there are no continuers, the meta communicative words list is empty and all the words in the lexicon are communicative words\n",
        "    else:\n",
        "      com_words = lexicon\n",
        "      meta_com_words = []\n",
        "\n",
        "    return lexicon, com_words, meta_com_words"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "jQhNSnuBd3-6",
        "outputId": "fe10c9d7-f6f5-4375-f205-398dd0721ade"
      },
      "source": [
        "# Test the initialisation\n",
        "agent_test = Agent(4, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASU0lEQVR4nO3dcYxdZZnH8e+zbbGlxha0lmlLAkQCSxQXduKi7BrTuqjUSmMIizHaGDb9x10KGhSyEar7B7AYS0k2JA2odWNArASo3RXZgjEbI7tTMIBUtrWu0jKlY3RGgy20+Owf90w7HWc6nXvunTt33u8nae497z3nnrcnp+fX85z3nBuZiSSpPH/W6Q5IkjrDAJCkQhkAklQoA0CSCmUASFKhDABJKtSEARARX42IAxHx3Ii20yPisYjYVb2eVrVHRNwVEbsj4pmIuLidnZckNe9kzgC+DnxwVNuNwPbMPBfYXk0DfAg4t/qzFri7Nd2UJLXahAGQmT8EfjOq+Qpgc/V+M7B6RPs3suHHwMKI6GlVZyVJrTO7yeUWZ2Z/9X4/sLh6vxR4ccR8e6u2fkaJiLU0zhKYP3/+X55//vlNdkWSyrRjx45fZ+aiZpdvNgCOysyMiEk/TyIzNwGbAHp7e7Ovr69uVySpKBHxyzrLNzsK6OXh0k71eqBq3wecOWK+ZVWbJGmaaTYAHgHWVO/XAA+PaP9kNRroEmBoRKlIkjSNTFgCioj7gPcBb4mIvcAtwG3AAxFxDfBL4Kpq9n8HLgd2A38APtWGPkuSWmDCAMjMj43z0Yox5k3g03U7JUlqP+8ElqRCGQCSVCgDQJIKZQBIUqEMAEkqlAEgSYUyACSpUAaAJBXKAJCkQhkAklQoA0CSCmUASFKhDABJKpQBIEmFMgAkqVAGgCQVygCQpEIZAJJUKANAkgplAEhSoQwASSqUASBJhTIAJKlQBoAkFcoAkKRCGQCSVCgDQJIKZQBIUqEMAEnHPPMAbHg7rF/YeH3mgU73SG00u9MdkDRNPPMAbL0WDh9sTA+92JgGuPCqzvVLbeMZgKSG7V86dvAfdvhgo10zkgEgdbtWlW2G9k6uXV3PAJCmuxMd4IfLNkMvAtl4fXAtrF8w+TBYsGxy7ep6BoA0nY11gN967bED+1hlG7LxMnreiay4GebMO75tzrxGu2YkA0Caziaqy09UnplMDf/Cq2DVXbDgTCAar6vu8gLwDFZrFFBEXA/8PY3/cjwLfAroAe4H3gzsAD6Rma/V7KdUponq8guWVWcHTXzHWC68ygN+QZo+A4iIpcC1QG9mvh2YBVwN3A5syMy3Ab8FrmlFR6UiTVSXH6tsc7LfoeLVLQHNBuZFxGzgVKAfWA5sqT7fDKyuuQ6pXBPV5Y8r2wDE+PNKozQdAJm5D/gy8CsaB/4hGiWfwcw8Us22F1g61vIRsTYi+iKib2BgoNluSDPbydTlL7wKrn8O1g/BRzdZw9dJi8xsbsGI04DvAH8HDALfpvE///VV+YeIOBP4j6pENK7e3t7s6+trqh+SVKqI2JGZvc0uX6cE9H7gF5k5kJmHgQeBS4GFVUkIYBmwr8Y6JEltUicAfgVcEhGnRkQAK4DngSeAK6t51gAP1+uiJKkd6lwDeJJGyecpGkNA/wzYBHwe+ExE7KYxFPTeFvRTktRite4DyMxbgFtGNe8B3lXneyVJ7eedwJJUKANAkgplAEhSoQwASSqUASBJhTIAJKlQBoAkFcoAkLpNq34DWMWrdSOYpCk2/BORw78SNvyzj+BTPzVpngFI3WSin4iUJsEAkLrJRD8RKU2CASB1k4l+IlKaBANA6iYT/USkNAkGgNRNTuYnIqWT5CggqdtceJUHfLWEZwCSVCgDQJIKZQBIUqEMAEkqlAEgSYUyACSpUAaAJBXKAJCkQhkAklQoA0CSCmUASFKhDABJKpQBIEmFMgAkqVAGgCQVygCQpEIZAJJUKANAkgplAEhSoWoFQEQsjIgtEfGziNgZEe+OiNMj4rGI2FW9ntaqzkqSWqfuGcBG4HuZeT7wTmAncCOwPTPPBbZX05KkaabpAIiIBcB7gXsBMvO1zBwErgA2V7NtBlbX7aQkqfXqnAGcDQwAX4uIpyPinoiYDyzOzP5qnv3A4rEWjoi1EdEXEX0DAwM1uiFJakadAJgNXAzcnZkXAa8wqtyTmQnkWAtn5qbM7M3M3kWLFtXohiSpGXUCYC+wNzOfrKa30AiElyOiB6B6PVCvi5Kkdmg6ADJzP/BiRJxXNa0AngceAdZUbWuAh2v1UJLUFrNrLv+PwDcj4hRgD/ApGqHyQERcA/wSuKrmOiSp7bbt2cbGpzay/5X9nDH/DNZdvI6V56zsdLfaqlYAZOZPgN4xPlpR53slaSpt27ON9T9az6HXDwHQ/0o/63+0HuCEIdDtoeGdwJKKt/GpjUcP/sMOvX6IjU9tHHeZ4dDof6WfJI+GxrY929rd3ZYxACQVb/8r+yfVDs2FxnRjAEgq3hnzz5hUOzQXGtONASCpeOsuXsfcWXOPa5s7ay7rLl437jLNhMZ0YwBIKt7Kc1ay/j3r6ZnfQxD0zO9h/XvWn/CCbjOhMd1E42bdzurt7c2+vr5Od0PSDDIVI3RGruNNp7yJiGDo1aEpGxEUETsyc6yRmCfFMwBJM85UjdBZec5Kvn/l97n1b27l1ddfZfDVwa4aEWQASJpxpnqETreOCDIAJM04Uz1Cp1tHBBkAkmacqR6h060jggwASTPOVI/Q6dYRQXUfBidJ087w6Jupek7PVK+vVRwGKkldymGgkqSmGACSVCgDQJIKZQBIUqEMAEkqlAEgSYUyACSpCdv2bOOyLZdx4eYLuWzLZdP+wW9j8UYwSZqkZn9EfrrxDECSJqlbn/45mgEgSZPUrU//HM0AkKRJ6tanf45mAEjSJHXr0z9H8yKwJE1Stz79czQDQJKasPKclV13wB/NEpAkFcoAkKRCGQCSVCgDQJIKZQBIUqEMAEkqlAEgSYUyACSpULUDICJmRcTTEfHdavrsiHgyInZHxLci4pT63ZQktVorzgDWATtHTN8ObMjMtwG/Ba5pwTokSS1WKwAiYhmwErinmg5gObClmmUzsLrOOiRJ7VH3DOBO4HPAH6vpNwODmXmkmt4LLB1rwYhYGxF9EdE3MDBQsxuSpMlqOgAi4sPAgczc0czymbkpM3szs3fRokXNdkOS1KQ6TwO9FPhIRFwOzAXeBGwEFkbE7OosYBmwr343JUmt1vQZQGbelJnLMvMs4Grg8cz8OPAEcGU12xrg4dq9lCS1XDvuA/g88JmI2E3jmsC9bViHJKmmlvwgTGb+APhB9X4P8K5WfK8kqX28E1iSCmUASFKhDABJKpQBIEmFMgAkqVAGgCQVygCQpEIZAJJUKANALTO0dSu7lq9g559fwK7lKxjaurXTXZJ0Ai25E1jq/+IXGbzv/qPTR156if4v3AzAglWrOtUtSSfgGYBqG9q6lcH7v/Un7XnoEAc23Nn2dXvWITXHMwDVdmDDnZA55mdH+vvbtt6hrVvp/8LN5KFDjXV51iFNimcAqu1EB/nZPT1tW++BDXcePfgPm4qzDmmmMABU24kO8m+9/rq2rXe84Dny0kuWgqSTYACotrdefx0xd+7xjREs/NjVbS3FnCh4+r9wsyEgTcAAUG0LVq2i55+/xOwlSyCC2UuWsORfbqfnllvaut4xg6diKUiamBeB1RILVq2a8guvw+t76YbPjfl5Oy9ASzOBZwDqagtWrWqceYyhnRegpZnAAFDXG6sUFHPntvUCtDQTWAJS1xsuBR3YcCdH+vuZ3dPDW6+/znsBpAkYAOq4oa1bax+8O3ENQup2BoA6yrt5pc7xGoA6yrt5pc4xANRR497N6xBOqe0MAHXUeEM1HcIptZ8BoI5yCKfUOV4EVkc5hFPqHANAHecQTqkzLAFJUqEMAEkqlAEgSYUyACSpUAaAJBXKAJCkQjUdABFxZkQ8ERHPR8RPI2Jd1X56RDwWEbuq19Na111JUqvUOQM4Anw2My8ALgE+HREXADcC2zPzXGB7NS1JmmaaDoDM7M/Mp6r3vwd2AkuBK4DN1WybgdV1OylJar2WXAOIiLOAi4AngcWZOfwox/3A4nGWWRsRfRHRNzAw0IpuSJImoXYARMQbge8A12Xm70Z+lpkJ5FjLZeamzOzNzN5FixbV7YYkaZJqPQsoIubQOPh/MzMfrJpfjoiezOyPiB7gQN1OSuqMh57exx2PvsBLgwdZsnAeN3zgPFZftLTT3VKL1BkFFMC9wM7M/MqIjx4B1lTv1wAPN989SZ3y0NP7uOnBZ9k3eJAE9g0e5KYHn+Whp/d1umtqkToloEuBTwDLI+In1Z/LgduAv42IXcD7q2lJXeaOR1/g4OHXj2s7ePh17nj0hQ71SK3WdAkoM/8LiHE+XtHs90qaHl4aPDhuu6WhmcE7gSWNacnCeWO2L5g3x9LQDGEASBrTDR84j3lzZh3XNm/OLCKwNDRDGACSxrT6oqXc+tF3sHThPAJYunAet370HQz+4fCY849XMtL05U9CSjrORPX9Ox59gX1jHOzHKxlp+vIMQNJRJzP0c7zS0A0fOG+Ke6u6DABJR53M0M/xSkOOAuo+loAkHXWioZ8jrb5oqQf8GcAzAElHjVfHt74/MxkAko5qZX3/oaf3celtj3P2jdu49LbHvU9gGrIEJOmo4bJO3bt8hy8mD19PGL6YPHId6jwDQNJxWlHfP9HFZANg+jAAJLX82T4nezFZneU1AKlw7XjssxeTu4MBIBWuHY999max7mAJSCpcO8o1rbqYrPYyAKTCLVk4ry3P9vFmsenPEpBUOMs15fIMQCqc5ZpyGQCSLNcUyhKQJBXKAJCkQhkAklQoA0CSCmUASFKhDABJKpQBIEmFMgAkqVAGgCQVygCQpEIZAJJUKANAkgplAEhSoQwASSqUASBJhTIAJKlQbQmAiPhgRLwQEbsj4sZ2rEOSVE/LAyAiZgH/CnwIuAD4WERc0Or1SJLqaccZwLuA3Zm5JzNfA+4HrmjDeiRJNbTjN4GXAi+OmN4L/NXomSJiLbC2mnw1Ip5rQ1+60VuAX3e6E9OE2+IYt8UxbotjzquzcMd+FD4zNwGbACKiLzN7O9WX6cRtcYzb4hi3xTFui2Mioq/O8u0oAe0DzhwxvaxqkyRNI+0IgP8Bzo2IsyPiFOBq4JE2rEeSVEPLS0CZeSQi/gF4FJgFfDUzfzrBYpta3Y8u5rY4xm1xjNviGLfFMbW2RWRmqzoiSeoi3gksSYUyACSpUB0PgFIfGxERZ0bEExHxfET8NCLWVe2nR8RjEbGrej2t032dKhExKyKejojvVtNnR8ST1b7xrWpQwYwXEQsjYktE/CwidkbEu0vdLyLi+urfx3MRcV9EzC1pv4iIr0bEgZH3SY23L0TDXdV2eSYiLp7o+zsaAIU/NuII8NnMvAC4BPh09Xe/EdiemecC26vpUqwDdo6Yvh3YkJlvA34LXNORXk29jcD3MvN84J00tklx+0VELAWuBXoz8+00BpVcTVn7xdeBD45qG29f+BBwbvVnLXD3RF/e6TOAYh8bkZn9mflU9f73NP6RL6Xx999czbYZWN2ZHk6tiFgGrATuqaYDWA5sqWYpYltExALgvcC9AJn5WmYOUuh+QWOk4ryImA2cCvRT0H6RmT8EfjOqebx94QrgG9nwY2BhRPSc6Ps7HQBjPTZiaYf60jERcRZwEfAksDgz+6uP9gOLO9StqXYn8Dngj9X0m4HBzDxSTZeyb5wNDABfq8ph90TEfArcLzJzH/Bl4Fc0DvxDwA7K3C9GGm9fmPTxtNMBULyIeCPwHeC6zPzdyM+yMUZ3xo/TjYgPAwcyc0en+zINzAYuBu7OzIuAVxhV7ilovziNxv9qzwaWAPP503JI0eruC50OgKIfGxERc2gc/L+ZmQ9WzS8Pn7ZVrwc61b8pdCnwkYj4PxplwOU06uALq1N/KGff2Avszcwnq+ktNAKhxP3i/cAvMnMgMw8DD9LYV0rcL0Yab1+Y9PG00wFQ7GMjqhr3vcDOzPzKiI8eAdZU79cAD09136ZaZt6Umcsy8ywa+8Djmflx4Angymq2UrbFfuDFiBh+yuMK4HkK3C9olH4uiYhTq38vw9uiuP1ilPH2hUeAT1ajgS4BhkaUisaWmR39A1wO/C/wc+CfOt2fKfx7/zWNU7dngJ9Ufy6nUfveDuwC/hM4vdN9neLt8j7gu9X7c4D/BnYD3wbe0On+TdE2+Augr9o3HgJOK3W/AL4I/Ax4Dvg34A0l7RfAfTSufxymcXZ4zXj7AhA0RlX+HHiWxuipE36/j4KQpEJ1ugQkSeoQA0CSCmUASFKhDABJKpQBIEmFMgAkqVAGgCQV6v8Blv4y5Wq2CwsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VEVHMBGKkhZ"
      },
      "source": [
        "## Production:\n",
        "\n",
        "Production begins by selecting one exemplar from a word category: An exemplar is chosen from the target word category with probability proportional to the exemplar's activation level. \n",
        "- **Activation level:** \n",
        "    - _\"Each new exemplar is associated with an initial activation value that decreases over time (i.e., memory decay; Hintzman, 1986; Nosofsky, 1986; Pierrehumbert, 2001).\"_ (Winter & Wedel, 2016)\n",
        "    - _\"Activation is calculated as an exponential function of recency, where exemplars that were stored 100 rounds previously have an activation level that is approximately .1% that of a new exemplar).\"_ (Wedel, 2012)\n",
        "    - _\"In the model runs shown here, the activation of a exemplar is modeled as $e^{0.2j}$, where $j$ is its list position; this results in a exemplar at position 100 having an activation that is approximately .01 times that of an exemplar at position 1.\"_ (Wedel, 2012; Appendix)\n",
        "    - _\"The probability of an exemplar being chosen as a production target is its activation relative to the total activation of all exemplars in the category.\"_ (Wedel, 2012; Appendix)\n",
        "    - _\"Exemplars at list positions greater than 100 are discarded after every round to keep computation efficient; preserving more exemplars slows the rate of change in the system but otherwise does not qualitatively change system behavior.\"_ (Wedel, 2012; Appendix)\n",
        "  \n",
        "Before this target is passed to the listener however, two biases are applied to it:\"\n",
        "- **Similarity biases:** Consists of the following two components:\n",
        "    - **Within-word category similarity bias:** _\"The segment exemplar values of this initial word target are stochastically biased toward the value at the same positions in all the word exemplars within the category\"_\n",
        "        - _\"At the word level, population vectors are calculated for the segment values in the target word relative to all segment values at the same position over all exemplars within that word category\"_ (Wedel, 2012; Appendix)\n",
        "    - **Within-segment-dimension similarity bias:** _\"each individual segment exemplar value in the target is also stochastically biased toward all other segment exemplars that reference the same dimension across the entire lexicon\"_ \n",
        "        - _\"At the segment level, population vectors are calculated for the segment values in the target word relative to all segment values on that dimension across the lexicon.\"_ (Wedel, 2012; Appendix)\n",
        "    - _\"To model the influence of both word and segment recency and similarity on production variation, the population vectors at each segment dimension at each level are combined to create a new output that combines information from both within-word category, and within-lexicon sources. The relative contribution of word versus segment population vectors to the output was fixed at .9.\"_ (Wedel, 2012; Appendix) Marieke: <span class=\"mark\"> --> Wait, what does that last bit mean exactly? That the segment-level population vector contributes 9/10th of what the word-level population vector contributes? Or the other way around? Or something else entirely? Not sure how to interpret this... The Wedel (2012) Appendix refers to the following two articles in this context: (Guenther and Gjaja 1996; Oudeyer 2002); maybe those references could help us? (Also quite likely they won't though.) </span> \n",
        "Jacqueline: I think the first option indeed, that the segment-level population contributes 9/10th of what the world-level population contributes, this also makes sense I guess, as the segments within a word should influence each other more, than over the entire lexicon (you produce the different sounds of a word closer to each other than the different sounds of all the words combined of your lexicon right?)\n",
        "    - _\"The population vector with respect to a particular point within a particular segment dimension is a weighted average of all segment exemplars mapped to the category, where both the Euclidean distance from the target exemplar and activation influence each exemplar’s contribution. This is conceptually the same as Nosofsky’s Generalized Context model (Nosofsky 1988), modified to take exemplar activation into account. The formula used to incorporate these factors is given below, where $p$ is the output population vector, y is each position within the segment dimension value of the target under production, $w_y$ is the activation of the exemplar, $x$ is the reference point chosen as the basis for production, and $k$ is a scaling factor influencing the fall off of the contribution to the population vector of the point $y$ relative to $x$:\"_ (Wedel, 2012; Appendix)\n",
        "\n",
        "$$ p = \\frac{\\sum_y yw_{y} e^{-k |x-y|}}{\\sum_{y} w_{y} e^{-k |x-y|}} $$\n",
        "\n",
        "- _\"The value of $k$ used in the simulations shown here is 0.2; a larger value of $k$ reduces the effect of more distant values on the population vector.\"_ (Wedel, 2012; Appendix). --> Let us start with $k = 0.2$ as well, but make $k$ into a parameter that we can change just in case.\n",
        "\n",
        "\n",
        "- **Random noise:** _\"Noise is added to values of the output target by adding a normally distributed random value. This random value is biased slightly toward the center of the dimension, (i.e. a scale value of 50), in a simple model of production-based lenition (Pierrehumbert 2001; see also e.g. Lindblom et al. 1984 for arguments that the packing of phoneme inventories is in part a consequence of effort-minimization processes). The results described below do not depend on this lenition bias, but they contribute to the illustration by imposing a tendency for each segment exemplar distribution to drift toward the center of each dimension which encourages category merger (see discussion below).\"_ \n",
        "    - _\"Finally, a Gaussian random variable with a standard deviation of 3 is added to the output to introduce noise. This variable is biased slightly toward the center of the dimensional space, creating a fixed attractor at the center of each segment dimension in the system. The bias is calculated using a parabolic response curve given below, where $b$ is the bias added to the output population vector, $p$ is the output population vector, $N$ is the number of points in the space and $G$ is a constant; $b$ is subtracted from outputs greater than $N/2$ (here, 50) and added to those below it.\"_ (Wedel, 2012; Appendix)\n",
        "    \n",
        "$$ b = \\frac{(p-N/2)^2}{G}$$\n",
        "\n",
        "- _\"The value of G used in these simulations was 5000, giving a bias toward the center of 0.5 at the edges of the continuum. All else being equal, this bias shifts the distributions of both categories toward the center of the dimension over time, i.e. toward 50, which corresponds to a simple model of articulatory undershoot (cf. Lindblom 1983; Pierrehumbert 2001).\"_ (Wedel, 2012; Appendix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjHSAE9bS6yp"
      },
      "source": [
        "class Production(Agent):\n",
        "\n",
        "  # def __init__(self, n_words, n_dimensions, n_exemplars = 5, n_continuers=0, similarity_bias_word=True, similarity_bias_segment=True, noise=True, anti_ambiguity_bias=True):\n",
        "  #       super().__init__(similarity_bias_word, similarity_bias_segment, noise, lexicon)\n",
        "\n",
        "  \n",
        "  def select_exemplar(self):\n",
        "\n",
        "    targets = []\n",
        "    self.total_activations = []\n",
        "    for word_index in range(self.n_words):\n",
        "\n",
        "      # Only store exemplars until position 100\n",
        "      self.exemplars = self.lexicon[word_index][0][:101]\n",
        "\n",
        "      print(\"Exemplars beginning: \", self.exemplars)\n",
        "      self.activation_exemplars = []\n",
        "      j = 1\n",
        "      for exemplar in self.exemplars: \n",
        "        # activation = math.exp(0.2*j)\n",
        "        activation = 1/(0.2*j)\n",
        "        self.activation_exemplars.append(activation)\n",
        "        j += 1\n",
        "\n",
        "      self.total_activations.append(self.activation_exemplars)\n",
        "      print(\"Activation exemplars: \", self.activation_exemplars)\n",
        "      activation_word = sum(self.activation_exemplars)\n",
        "      print(\"Activation word: \", activation_word)\n",
        "\n",
        "      exemplar_probs = [activation/activation_word for activation in self.activation_exemplars]\n",
        "      print(\"Exemplars probability: \", exemplar_probs)\n",
        "      # max_prob = max(exemplar_probs)\n",
        "      # print(\"Max probability: \", max_prob)\n",
        "      target = random.choices(self.exemplars, weights = exemplar_probs, k = 1)\n",
        "      print(\"Chose exemplar: \", target)\n",
        "\n",
        "      targets.append(target[0])\n",
        "      print(targets)\n",
        "\n",
        "    return self.add_biases(targets)\n",
        "\n",
        "  def add_biases(self, targets, k=0.2):\n",
        "    \n",
        "    target_exemplars = []\n",
        "    for target in targets:\n",
        "\n",
        "      if self.similarity_bias_word:\n",
        "        word_bias = self.similarity_word(target, k)\n",
        "\n",
        "      if self.similarity_bias_segment:\n",
        "        segment_bias = self.similarity_segment(target, k)\n",
        "\n",
        "        if self.similarity_bias_word:\n",
        "          total_bias = [(9*a) + b for a, b in zip(word_bias, segment_bias)]\n",
        "          target_exemplar = [bias / 10 for bias in total_bias]\n",
        "\n",
        "          if self.noise:\n",
        "            print(\"Before Noise:\", target_exemplar)\n",
        "            exemplar = self.added_noise(target_exemplar)\n",
        "        \n",
        "        elif self.noise:\n",
        "          exemplar = self.added_noise(target)\n",
        "\n",
        "        target_exemplars.append(exemplar)\n",
        "\n",
        "    print(\"FINAL:\", target_exemplars)\n",
        "    print(\"BEFORE BIASES:\", targets)\n",
        "\n",
        "    return target_exemplars\n",
        "\n",
        "  def similarity_word(self, target, k):\n",
        "\n",
        "    final = []\n",
        "    for dimension in range(self.n_dimensions):\n",
        "      index = 0\n",
        "      sum = 0\n",
        "      sum2 = 0\n",
        "      for exemplar in self.exemplars:\n",
        "        sum += exemplar[dimension] * self.activation_exemplars[index] * math.exp(-k * abs(target[dimension]-exemplar[dimension]))\n",
        "        sum2 += self.activation_exemplars[index] * math.exp(-k * abs(target[dimension]-exemplar[dimension]))\n",
        "        index += 1\n",
        "      final.append(sum/sum2)\n",
        "\n",
        "    return final\n",
        "\n",
        "  def similarity_segment(self, target, k):\n",
        "\n",
        "    final = []\n",
        "    for dimension in range(self.n_dimensions):\n",
        "      word_index = 0\n",
        "      sum = 0\n",
        "      sum2 = 0\n",
        "      for word in self.lexicon:\n",
        "        index = 0\n",
        "        print(\"word_index:\", word_index)\n",
        "        for exemplar in word[0]:\n",
        "          print(\"Ex dimension: \", exemplar[dimension])\n",
        "          print(\"activations: \", self.total_activations[word_index][index])\n",
        "          print(\"Math: \", math.exp(-k * abs(target[dimension]-exemplar[dimension])))\n",
        "          sum += exemplar[dimension] * self.total_activations[word_index][index] * math.exp(-k * abs(target[dimension]-exemplar[dimension]))\n",
        "          print(\"sum: \", sum)\n",
        "          sum2 += self.total_activations[word_index][index] * math.exp(-k * abs(target[dimension]-exemplar[dimension]))\n",
        "          index += 1\n",
        "        word_index += 1\n",
        "      final.append(sum/sum2)\n",
        "\n",
        "    return final\n",
        "\n",
        "  def added_noise(self, target_biases, G = 5000):\n",
        "\n",
        "    target_noise = []\n",
        "    for segment in target_biases:\n",
        "      N = 100\n",
        "      bias = ((segment - (N/2))**2)/G\n",
        "\n",
        "      if segment > N/2:\n",
        "        new_target = segment - bias\n",
        "      else:\n",
        "        new_target = segment + bias\n",
        "\n",
        "      added_noise = np.random.normal(segment, 3, 1)\n",
        "      target_noise.append(bias + added_noise)\n",
        "\n",
        "      #target_noise.append(new_target)\n",
        "\n",
        "    return target_noise"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0cSEPbDr4h8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ff01443-d4a7-4070-d744-2be9966a0ce7"
      },
      "source": [
        "test = Production(4, 2).select_exemplar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Exemplars beginning:  [[21.644129087103153, 23.424250383480523], [20.682304597222515, 18.59602112198236], [21.504071049965532, 23.832289683279985], [22.605489592319156, 26.287180834522964], [16.457500713636154, 26.744303925171643]]\n",
            "Activation exemplars:  [5.0, 2.5, 1.6666666666666665, 1.25, 1.0]\n",
            "Activation word:  11.416666666666666\n",
            "Exemplars probability:  [0.43795620437956206, 0.21897810218978103, 0.145985401459854, 0.10948905109489052, 0.08759124087591241]\n",
            "Chose exemplar:  [[21.644129087103153, 23.424250383480523]]\n",
            "[[21.644129087103153, 23.424250383480523]]\n",
            "Exemplars beginning:  [[56.46379820299609, 8.100757618344813], [63.626926218495925, 10.296410238730422], [59.1143996845294, 13.93435581338081], [59.27213657603203, 16.212086332622103], [60.47973745093733, 9.962497960778776]]\n",
            "Activation exemplars:  [5.0, 2.5, 1.6666666666666665, 1.25, 1.0]\n",
            "Activation word:  11.416666666666666\n",
            "Exemplars probability:  [0.43795620437956206, 0.21897810218978103, 0.145985401459854, 0.10948905109489052, 0.08759124087591241]\n",
            "Chose exemplar:  [[59.27213657603203, 16.212086332622103]]\n",
            "[[21.644129087103153, 23.424250383480523], [59.27213657603203, 16.212086332622103]]\n",
            "Exemplars beginning:  [[88.80232084986767, 32.668704657005094], [89.4523172729938, 33.46584330645799], [89.6498302612973, 32.666231284910005], [91.12814660478897, 36.82339877229258], [89.18197797957788, 35.85122194832088]]\n",
            "Activation exemplars:  [5.0, 2.5, 1.6666666666666665, 1.25, 1.0]\n",
            "Activation word:  11.416666666666666\n",
            "Exemplars probability:  [0.43795620437956206, 0.21897810218978103, 0.145985401459854, 0.10948905109489052, 0.08759124087591241]\n",
            "Chose exemplar:  [[89.18197797957788, 35.85122194832088]]\n",
            "[[21.644129087103153, 23.424250383480523], [59.27213657603203, 16.212086332622103], [89.18197797957788, 35.85122194832088]]\n",
            "Exemplars beginning:  [[35.84764156297297, 24.20586804324914], [39.396819357865, 27.765651478285616], [39.54888991452113, 27.436767342784186], [40.32494343838476, 24.037267840313074], [35.9520768215862, 24.0241902476142]]\n",
            "Activation exemplars:  [5.0, 2.5, 1.6666666666666665, 1.25, 1.0]\n",
            "Activation word:  11.416666666666666\n",
            "Exemplars probability:  [0.43795620437956206, 0.21897810218978103, 0.145985401459854, 0.10948905109489052, 0.08759124087591241]\n",
            "Chose exemplar:  [[39.396819357865, 27.765651478285616]]\n",
            "[[21.644129087103153, 23.424250383480523], [59.27213657603203, 16.212086332622103], [89.18197797957788, 35.85122194832088], [39.396819357865, 27.765651478285616]]\n",
            "word_index: 0\n",
            "Ex dimension:  21.644129087103153\n",
            "activations:  5.0\n",
            "Math:  1.0\n",
            "sum:  108.22064543551576\n",
            "Ex dimension:  20.682304597222515\n",
            "activations:  2.5\n",
            "Math:  0.8250057706240279\n",
            "sum:  150.87819704179685\n",
            "Ex dimension:  21.504071049965532\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.9723770799392597\n",
            "sum:  185.7283067324166\n",
            "Ex dimension:  22.605489592319156\n",
            "activations:  1.25\n",
            "Math:  0.8250823321814726\n",
            "sum:  209.04254432358496\n",
            "Ex dimension:  16.457500713636154\n",
            "activations:  1.0\n",
            "Math:  0.3544011998437195\n",
            "sum:  214.8751023229265\n",
            "word_index: 1\n",
            "Ex dimension:  56.46379820299609\n",
            "activations:  5.0\n",
            "Math:  0.000945370330435232\n",
            "sum:  215.14199832075047\n",
            "Ex dimension:  63.626926218495925\n",
            "activations:  2.5\n",
            "Math:  0.00022564232925176037\n",
            "sum:  215.17789064033815\n",
            "Ex dimension:  59.1143996845294\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.0005563827398660247\n",
            "sum:  215.23270769310818\n",
            "Ex dimension:  59.27213657603203\n",
            "activations:  1.25\n",
            "Math:  0.000539104300806479\n",
            "sum:  215.27265002279086\n",
            "Ex dimension:  60.47973745093733\n",
            "activations:  1.0\n",
            "Math:  0.00042343028540178313\n",
            "sum:  215.29825897528073\n",
            "word_index: 2\n",
            "Ex dimension:  88.80232084986767\n",
            "activations:  5.0\n",
            "Math:  1.4679578326271876e-06\n",
            "sum:  215.29891076559298\n",
            "Ex dimension:  89.4523172729938\n",
            "activations:  2.5\n",
            "Math:  1.2890079877374512e-06\n",
            "sum:  215.2991990274717\n",
            "Ex dimension:  89.6498302612973\n",
            "activations:  1.6666666666666665\n",
            "Math:  1.2390814303485768e-06\n",
            "sum:  215.29938416653823\n",
            "Ex dimension:  91.12814660478897\n",
            "activations:  1.25\n",
            "Math:  9.219235784514867e-07\n",
            "sum:  215.299489183022\n",
            "Ex dimension:  89.18197797957788\n",
            "activations:  1.0\n",
            "Math:  1.3606204098884888e-06\n",
            "sum:  215.29961052584142\n",
            "word_index: 3\n",
            "Ex dimension:  35.84764156297297\n",
            "activations:  5.0\n",
            "Math:  0.05838463662926751\n",
            "sum:  225.76436815919342\n",
            "Ex dimension:  39.396819357865\n",
            "activations:  2.5\n",
            "Math:  0.028709188399776733\n",
            "sum:  228.5919949324357\n",
            "Ex dimension:  39.54888991452113\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.0278491686098479\n",
            "sum:  230.4276677717054\n",
            "Ex dimension:  40.32494343838476\n",
            "activations:  1.25\n",
            "Math:  0.02384542580338563\n",
            "sum:  231.62962458018754\n",
            "Ex dimension:  35.9520768215862\n",
            "activations:  1.0\n",
            "Math:  0.057177801196319586\n",
            "sum:  233.685285281287\n",
            "word_index: 0\n",
            "Ex dimension:  23.424250383480523\n",
            "activations:  5.0\n",
            "Math:  1.0\n",
            "sum:  117.12125191740262\n",
            "Ex dimension:  18.59602112198236\n",
            "activations:  2.5\n",
            "Math:  0.38073722030540613\n",
            "sum:  134.82174539421308\n",
            "Ex dimension:  23.832289683279985\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.9216332971621917\n",
            "sum:  171.42946492708944\n",
            "Ex dimension:  26.287180834522964\n",
            "activations:  1.25\n",
            "Math:  0.5640648283489582\n",
            "sum:  189.96405760859346\n",
            "Ex dimension:  26.744303925171643\n",
            "activations:  1.0\n",
            "Math:  0.5147825459617074\n",
            "sum:  203.731558473167\n",
            "word_index: 1\n",
            "Ex dimension:  8.100757618344813\n",
            "activations:  5.0\n",
            "Math:  0.046667907643810645\n",
            "sum:  205.62178551505608\n",
            "Ex dimension:  10.296410238730422\n",
            "activations:  2.5\n",
            "Math:  0.07239862083950438\n",
            "sum:  207.48540026726067\n",
            "Ex dimension:  13.93435581338081\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.14987121594599645\n",
            "sum:  210.96599834921992\n",
            "Ex dimension:  16.212086332622103\n",
            "activations:  1.25\n",
            "Math:  0.23635205898882347\n",
            "sum:  215.75569833074468\n",
            "Ex dimension:  9.962497960778776\n",
            "activations:  1.0\n",
            "Math:  0.06772157363989989\n",
            "sum:  216.43037437003292\n",
            "word_index: 2\n",
            "Ex dimension:  32.668704657005094\n",
            "activations:  5.0\n",
            "Math:  0.15741166192946388\n",
            "sum:  242.14254983574287\n",
            "Ex dimension:  33.46584330645799\n",
            "activations:  2.5\n",
            "Math:  0.13421415480018328\n",
            "sum:  253.37152452087196\n",
            "Ex dimension:  32.666231284910005\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.15748954871458729\n",
            "sum:  261.94584122631665\n",
            "Ex dimension:  36.82339877229258\n",
            "activations:  1.25\n",
            "Math:  0.06857483297866312\n",
            "sum:  265.1022892519625\n",
            "Ex dimension:  35.85122194832088\n",
            "activations:  1.0\n",
            "Math:  0.08329270464235762\n",
            "sum:  268.08843449277157\n",
            "word_index: 3\n",
            "Ex dimension:  24.20586804324914\n",
            "activations:  5.0\n",
            "Math:  0.8552824344067447\n",
            "sum:  371.60270322756435\n",
            "Ex dimension:  27.765651478285616\n",
            "activations:  2.5\n",
            "Math:  0.41967267408896536\n",
            "sum:  400.73391623685023\n",
            "Ex dimension:  27.436767342784186\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.44820552443724804\n",
            "sum:  421.2294340630758\n",
            "Ex dimension:  24.037267840313074\n",
            "activations:  1.25\n",
            "Math:  0.8846143502580627\n",
            "sum:  447.80907415374776\n",
            "Ex dimension:  24.0241902476142\n",
            "activations:  1.0\n",
            "Math:  0.8869311039270698\n",
            "sum:  469.1168757310182\n",
            "Before Noise: [35.497687660508284, 24.85640883502824]\n",
            "word_index: 0\n",
            "Ex dimension:  21.644129087103153\n",
            "activations:  5.0\n",
            "Math:  0.000539104300806479\n",
            "sum:  0.0583422153903396\n",
            "Ex dimension:  20.682304597222515\n",
            "activations:  2.5\n",
            "Math:  0.00044476415913357725\n",
            "sum:  0.08133908492316008\n",
            "Ex dimension:  21.504071049965532\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.0005242126658009001\n",
            "sum:  0.10012692894095074\n",
            "Ex dimension:  22.605489592319156\n",
            "activations:  1.25\n",
            "Math:  0.0006533945520092717\n",
            "sum:  0.11858980862235527\n",
            "Ex dimension:  16.457500713636154\n",
            "activations:  1.0\n",
            "Math:  0.00019105921104672558\n",
            "sum:  0.12173416572450352\n",
            "word_index: 1\n",
            "Ex dimension:  56.46379820299609\n",
            "activations:  5.0\n",
            "Math:  0.570257266862061\n",
            "sum:  161.116190365182\n",
            "Ex dimension:  63.626926218495925\n",
            "activations:  2.5\n",
            "Math:  0.4185504157807839\n",
            "sum:  227.69388142419382\n",
            "Ex dimension:  59.1143996845294\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.9689450483965293\n",
            "sum:  323.15822286295736\n",
            "Ex dimension:  59.27213657603203\n",
            "activations:  1.25\n",
            "Math:  1.0\n",
            "sum:  397.2483935829974\n",
            "Ex dimension:  60.47973745093733\n",
            "activations:  1.0\n",
            "Math:  0.785432957534095\n",
            "sum:  444.75117263997265\n",
            "word_index: 2\n",
            "Ex dimension:  88.80232084986767\n",
            "activations:  5.0\n",
            "Math:  0.002722957005594613\n",
            "sum:  445.9601971483287\n",
            "Ex dimension:  89.4523172729938\n",
            "activations:  2.5\n",
            "Math:  0.0023910178156789823\n",
            "sum:  446.4949023589624\n",
            "Ex dimension:  89.6498302612973\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.002298407615177546\n",
            "sum:  446.838322113249\n",
            "Ex dimension:  91.12814660478897\n",
            "activations:  1.25\n",
            "Math:  0.0017101024367127582\n",
            "sum:  447.03312019520143\n",
            "Ex dimension:  89.18197797957788\n",
            "activations:  1.0\n",
            "Math:  0.002523853747508701\n",
            "sum:  447.25820246453543\n",
            "word_index: 3\n",
            "Ex dimension:  35.84764156297297\n",
            "activations:  5.0\n",
            "Math:  0.009233667141403981\n",
            "sum:  448.91322841451966\n",
            "Ex dimension:  39.396819357865\n",
            "activations:  2.5\n",
            "Math:  0.018778110105358167\n",
            "sum:  450.7627229437769\n",
            "Ex dimension:  39.54888991452113\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.01935800340609964\n",
            "sum:  452.0387021865648\n",
            "Ex dimension:  40.32494343838476\n",
            "activations:  1.25\n",
            "Math:  0.02260828996100106\n",
            "sum:  453.1782997039598\n",
            "Ex dimension:  35.9520768215862\n",
            "activations:  1.0\n",
            "Math:  0.009428559502585069\n",
            "sum:  453.51727599951363\n",
            "word_index: 0\n",
            "Ex dimension:  23.424250383480523\n",
            "activations:  5.0\n",
            "Math:  0.23635205898882347\n",
            "sum:  27.681849042026798\n",
            "Ex dimension:  18.59602112198236\n",
            "activations:  2.5\n",
            "Math:  0.6207747663841088\n",
            "sum:  56.54170071120818\n",
            "Ex dimension:  23.832289683279985\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.2178299274169422\n",
            "sum:  65.19401059768887\n",
            "Ex dimension:  26.287180834522964\n",
            "activations:  1.25\n",
            "Math:  0.13331788358345356\n",
            "sum:  69.57469974048153\n",
            "Ex dimension:  26.744303925171643\n",
            "activations:  1.0\n",
            "Math:  0.12166991466955818\n",
            "sum:  72.8286769169539\n",
            "word_index: 1\n",
            "Ex dimension:  8.100757618344813\n",
            "activations:  5.0\n",
            "Math:  0.19745081910209833\n",
            "sum:  80.82618305240263\n",
            "Ex dimension:  10.296410238730422\n",
            "activations:  2.5\n",
            "Math:  0.30631686116568996\n",
            "sum:  88.71109321640806\n",
            "Ex dimension:  13.93435581338081\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.6341015880597152\n",
            "sum:  103.43742179949788\n",
            "Ex dimension:  16.212086332622103\n",
            "activations:  1.25\n",
            "Math:  1.0\n",
            "sum:  123.70252971527552\n",
            "Ex dimension:  9.962497960778776\n",
            "activations:  1.0\n",
            "Math:  0.2865283845193931\n",
            "sum:  126.55706816175521\n",
            "word_index: 2\n",
            "Ex dimension:  32.668704657005094\n",
            "activations:  5.0\n",
            "Math:  0.037204570405881376\n",
            "sum:  132.63419377415767\n",
            "Ex dimension:  33.46584330645799\n",
            "activations:  2.5\n",
            "Math:  0.03172179183246801\n",
            "sum:  135.2881850613213\n",
            "Ex dimension:  32.666231284910005\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.03722297910791333\n",
            "sum:  137.3147424690754\n",
            "Ex dimension:  36.82339877229258\n",
            "activations:  1.25\n",
            "Math:  0.01620780296932171\n",
            "sum:  138.060775459028\n",
            "Ex dimension:  35.85122194832088\n",
            "activations:  1.0\n",
            "Math:  0.019686402240969153\n",
            "sum:  138.7665570351329\n",
            "word_index: 3\n",
            "Ex dimension:  24.20586804324914\n",
            "activations:  5.0\n",
            "Math:  0.20214776438900744\n",
            "sum:  163.23236758532357\n",
            "Ex dimension:  27.765651478285616\n",
            "activations:  2.5\n",
            "Math:  0.0991905006222724\n",
            "sum:  170.1175897609103\n",
            "Ex dimension:  27.436767342784186\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.10593429855090901\n",
            "sum:  174.96174759918085\n",
            "Ex dimension:  24.037267840313074\n",
            "activations:  1.25\n",
            "Math:  0.20908042309455335\n",
            "sum:  181.24390026179304\n",
            "Ex dimension:  24.0241902476142\n",
            "activations:  1.0\n",
            "Math:  0.20962799259439313\n",
            "sum:  186.2800430371062\n",
            "Before Noise: [40.40107349852434, 24.294450249295767]\n",
            "word_index: 0\n",
            "Ex dimension:  21.644129087103153\n",
            "activations:  5.0\n",
            "Math:  1.3606204098884888e-06\n",
            "sum:  0.00014724721895086827\n",
            "Ex dimension:  20.682304597222515\n",
            "activations:  2.5\n",
            "Math:  1.1225196897868343e-06\n",
            "sum:  0.00020528795430224586\n",
            "Ex dimension:  21.504071049965532\n",
            "activations:  1.6666666666666665\n",
            "Math:  1.3230361010731293e-06\n",
            "sum:  0.0002527057248341558\n",
            "Ex dimension:  22.605489592319156\n",
            "activations:  1.25\n",
            "Math:  1.6490722886903707e-06\n",
            "sum:  0.0002993033329078709\n",
            "Ex dimension:  16.457500713636154\n",
            "activations:  1.0\n",
            "Math:  4.822055057963342e-07\n",
            "sum:  0.0003072392303636334\n",
            "word_index: 1\n",
            "Ex dimension:  56.46379820299609\n",
            "activations:  5.0\n",
            "Math:  0.0014392459400138825\n",
            "sum:  0.40663370083749\n",
            "Ex dimension:  63.626926218495925\n",
            "activations:  2.5\n",
            "Math:  0.006029987433653803\n",
            "sum:  1.3658076146863602\n",
            "Ex dimension:  59.1143996845294\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.002445475591525581\n",
            "sum:  1.606745650580034\n",
            "Ex dimension:  59.27213657603203\n",
            "activations:  1.25\n",
            "Math:  0.002523853747508701\n",
            "sum:  1.7937384056053665\n",
            "Ex dimension:  60.47973745093733\n",
            "activations:  1.0\n",
            "Math:  0.003213328041940668\n",
            "sum:  1.9880796419256725\n",
            "word_index: 2\n",
            "Ex dimension:  88.80232084986767\n",
            "activations:  5.0\n",
            "Math:  0.926879764286828\n",
            "sum:  413.5334507291687\n",
            "Ex dimension:  89.4523172729938\n",
            "activations:  2.5\n",
            "Math:  0.9473678171879645\n",
            "sum:  625.3940671224722\n",
            "Ex dimension:  89.6498302612973\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.9106738524156984\n",
            "sum:  761.4636609432539\n",
            "Ex dimension:  91.12814660478897\n",
            "activations:  1.25\n",
            "Math:  0.6775758850530869\n",
            "sum:  838.646454179488\n",
            "Ex dimension:  89.18197797957788\n",
            "activations:  1.0\n",
            "Math:  1.0\n",
            "sum:  927.8284321590659\n",
            "word_index: 3\n",
            "Ex dimension:  35.84764156297297\n",
            "activations:  5.0\n",
            "Math:  2.3304425418080418e-05\n",
            "sum:  927.832609202512\n",
            "Ex dimension:  39.396819357865\n",
            "activations:  2.5\n",
            "Math:  4.7393203560539185e-05\n",
            "sum:  927.8372770562106\n",
            "Ex dimension:  39.54888991452113\n",
            "activations:  1.6666666666666665\n",
            "Math:  4.885676944077075e-05\n",
            "sum:  927.8404974412043\n",
            "Ex dimension:  40.32494343838476\n",
            "activations:  1.25\n",
            "Math:  5.70600173428359e-05\n",
            "sum:  927.8433736186693\n",
            "Ex dimension:  35.9520768215862\n",
            "activations:  1.0\n",
            "Math:  2.379630523420808e-05\n",
            "sum:  927.8442291452631\n",
            "word_index: 0\n",
            "Ex dimension:  23.424250383480523\n",
            "activations:  5.0\n",
            "Math:  0.08329270464235762\n",
            "sum:  9.755345843299377\n",
            "Ex dimension:  18.59602112198236\n",
            "activations:  2.5\n",
            "Math:  0.03171263283725043\n",
            "sum:  11.229667818487329\n",
            "Ex dimension:  23.832289683279985\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.09037510352417259\n",
            "sum:  14.819410564061494\n",
            "Ex dimension:  26.287180834522964\n",
            "activations:  1.25\n",
            "Math:  0.14766512722688083\n",
            "sum:  19.671535442018815\n",
            "Ex dimension:  26.744303925171643\n",
            "activations:  1.0\n",
            "Math:  0.16180172637118398\n",
            "sum:  23.99880998770722\n",
            "word_index: 1\n",
            "Ex dimension:  8.100757618344813\n",
            "activations:  5.0\n",
            "Math:  0.003887096247652745\n",
            "sum:  24.156252110414282\n",
            "Ex dimension:  10.296410238730422\n",
            "activations:  2.5\n",
            "Math:  0.006030276942098878\n",
            "sum:  24.3114776235368\n",
            "Ex dimension:  13.93435581338081\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.012483178924180884\n",
            "sum:  24.601386051556187\n",
            "Ex dimension:  16.212086332622103\n",
            "activations:  1.25\n",
            "Math:  0.019686402240969153\n",
            "sum:  25.000333117442832\n",
            "Ex dimension:  9.962497960778776\n",
            "activations:  1.0\n",
            "Math:  0.005640713031103851\n",
            "sum:  25.05652870951254\n",
            "word_index: 2\n",
            "Ex dimension:  32.668704657005094\n",
            "activations:  5.0\n",
            "Math:  0.5291393510582529\n",
            "sum:  111.48801462011954\n",
            "Ex dimension:  33.46584330645799\n",
            "activations:  2.5\n",
            "Math:  0.620595530824323\n",
            "sum:  163.4098965982568\n",
            "Ex dimension:  32.666231284910005\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.5288776640874501\n",
            "sum:  192.20396342576277\n",
            "Ex dimension:  36.82339877229258\n",
            "activations:  1.25\n",
            "Math:  0.8232993906622423\n",
            "sum:  230.09981563993932\n",
            "Ex dimension:  35.85122194832088\n",
            "activations:  1.0\n",
            "Math:  1.0\n",
            "sum:  265.9510375882602\n",
            "word_index: 3\n",
            "Ex dimension:  24.20586804324914\n",
            "activations:  5.0\n",
            "Math:  0.09738619816287059\n",
            "sum:  277.737624898081\n",
            "Ex dimension:  27.765651478285616\n",
            "activations:  2.5\n",
            "Math:  0.19847064101366915\n",
            "sum:  291.51429151572466\n",
            "Ex dimension:  27.436767342784186\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.1858359616315242\n",
            "sum:  300.0121882544025\n",
            "Ex dimension:  24.037267840313074\n",
            "activations:  1.25\n",
            "Math:  0.09415708056065245\n",
            "sum:  302.8412869600254\n",
            "Ex dimension:  24.0241902476142\n",
            "activations:  1.0\n",
            "Math:  0.09391113275153172\n",
            "sum:  305.09742587961716\n",
            "Before Noise: [43.46630354332617, 26.56689513758988]\n",
            "word_index: 0\n",
            "Ex dimension:  21.644129087103153\n",
            "activations:  5.0\n",
            "Math:  0.028709188399776733\n",
            "sum:  3.10692689855366\n",
            "Ex dimension:  20.682304597222515\n",
            "activations:  2.5\n",
            "Math:  0.0236852460997482\n",
            "sum:  4.3315905842915825\n",
            "Ex dimension:  21.504071049965532\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.02791615678360096\n",
            "sum:  5.332108949152469\n",
            "Ex dimension:  22.605489592319156\n",
            "activations:  1.25\n",
            "Math:  0.03479554376576117\n",
            "sum:  6.315321827222469\n",
            "Ex dimension:  16.457500713636154\n",
            "activations:  1.0\n",
            "Math:  0.010174570815420263\n",
            "sum:  6.48276983367819\n",
            "word_index: 1\n",
            "Ex dimension:  56.46379820299609\n",
            "activations:  5.0\n",
            "Math:  0.03292919037873547\n",
            "sum:  15.77930563634299\n",
            "Ex dimension:  63.626926218495925\n",
            "activations:  2.5\n",
            "Math:  0.007859585792175001\n",
            "sum:  17.029508849609634\n",
            "Ex dimension:  59.1143996845294\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.019379953627332483\n",
            "sum:  18.938899390599264\n",
            "Ex dimension:  59.27213657603203\n",
            "activations:  1.25\n",
            "Math:  0.018778110105358167\n",
            "sum:  20.33017277410496\n",
            "Ex dimension:  60.47973745093733\n",
            "activations:  1.0\n",
            "Math:  0.01474894655695234\n",
            "sum:  21.222185189547343\n",
            "word_index: 2\n",
            "Ex dimension:  88.80232084986767\n",
            "activations:  5.0\n",
            "Math:  5.113198646321202e-05\n",
            "sum:  21.24488838488533\n",
            "Ex dimension:  89.4523172729938\n",
            "activations:  2.5\n",
            "Math:  4.489879580669287e-05\n",
            "sum:  21.254929138204517\n",
            "Ex dimension:  89.6498302612973\n",
            "activations:  1.6666666666666665\n",
            "Math:  4.3159751264797616e-05\n",
            "sum:  21.261377912162864\n",
            "Ex dimension:  91.12814660478897\n",
            "activations:  1.25\n",
            "Math:  3.2112491848033446e-05\n",
            "sum:  21.265035851994078\n",
            "Ex dimension:  89.18197797957788\n",
            "activations:  1.0\n",
            "Math:  4.7393203560539185e-05\n",
            "sum:  21.269262471630395\n",
            "word_index: 3\n",
            "Ex dimension:  35.84764156297297\n",
            "activations:  5.0\n",
            "Math:  0.491725050582659\n",
            "sum:  109.40517927573995\n",
            "Ex dimension:  39.396819357865\n",
            "activations:  2.5\n",
            "Math:  1.0\n",
            "sum:  207.89722767040246\n",
            "Ex dimension:  39.54888991452113\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.9700437442552186\n",
            "sum:  271.837483093435\n",
            "Ex dimension:  40.32494343838476\n",
            "activations:  1.25\n",
            "Math:  0.8305851587072756\n",
            "sum:  313.70410752547593\n",
            "Ex dimension:  35.9520768215862\n",
            "activations:  1.0\n",
            "Math:  0.502103750041103\n",
            "sum:  331.75578011936017\n",
            "word_index: 0\n",
            "Ex dimension:  23.424250383480523\n",
            "activations:  5.0\n",
            "Math:  0.41967267408896536\n",
            "sum:  49.152588984823716\n",
            "Ex dimension:  18.59602112198236\n",
            "activations:  2.5\n",
            "Math:  0.1597850073707693\n",
            "sum:  56.58100241493105\n",
            "Ex dimension:  23.832289683279985\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.4553575433756384\n",
            "sum:  74.66802388692263\n",
            "Ex dimension:  26.287180834522964\n",
            "activations:  1.25\n",
            "Math:  0.7440149660055301\n",
            "sum:  99.11559383064616\n",
            "Ex dimension:  26.744303925171643\n",
            "activations:  1.0\n",
            "Math:  0.8152426250290605\n",
            "sum:  120.9186903671781\n",
            "word_index: 1\n",
            "Ex dimension:  8.100757618344813\n",
            "activations:  5.0\n",
            "Math:  0.01958524559501488\n",
            "sum:  121.71196700448296\n",
            "Ex dimension:  10.296410238730422\n",
            "activations:  2.5\n",
            "Math:  0.0303837228080679\n",
            "sum:  122.4940751910123\n",
            "Ex dimension:  13.93435581338081\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.06289685396502111\n",
            "sum:  123.95478709549705\n",
            "Ex dimension:  16.212086332622103\n",
            "activations:  1.25\n",
            "Math:  0.0991905006222724\n",
            "sum:  125.9648932948274\n",
            "Ex dimension:  9.962497960778776\n",
            "activations:  1.0\n",
            "Math:  0.028420893902969573\n",
            "sum:  126.24803639237925\n",
            "word_index: 2\n",
            "Ex dimension:  32.668704657005094\n",
            "activations:  5.0\n",
            "Math:  0.3750819904373726\n",
            "sum:  187.51525023117992\n",
            "Ex dimension:  33.46584330645799\n",
            "activations:  2.5\n",
            "Math:  0.31980675199198605\n",
            "sum:  214.2717568574576\n",
            "Ex dimension:  32.666231284910005\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.3752675798024474\n",
            "sum:  234.70271945004956\n",
            "Ex dimension:  36.82339877229258\n",
            "activations:  1.25\n",
            "Math:  0.16340075781089847\n",
            "sum:  242.22393353075645\n",
            "Ex dimension:  35.85122194832088\n",
            "activations:  1.0\n",
            "Math:  0.19847064101366915\n",
            "sum:  249.33934853196303\n",
            "word_index: 3\n",
            "Ex dimension:  24.20586804324914\n",
            "activations:  5.0\n",
            "Math:  0.4906831441944271\n",
            "sum:  308.7264057290475\n",
            "Ex dimension:  27.765651478285616\n",
            "activations:  2.5\n",
            "Math:  1.0\n",
            "sum:  378.14053442476154\n",
            "Ex dimension:  27.436767342784186\n",
            "activations:  1.6666666666666665\n",
            "Math:  0.936339806645383\n",
            "sum:  420.9574301392897\n",
            "Ex dimension:  24.037267840313074\n",
            "activations:  1.25\n",
            "Math:  0.47441314281928276\n",
            "sum:  435.21192486542947\n",
            "Ex dimension:  24.0241902476142\n",
            "activations:  1.0\n",
            "Math:  0.4731739277501694\n",
            "sum:  446.5795453259104\n",
            "Before Noise: [38.25647928165351, 26.089992583535167]\n",
            "FINAL: [[array([38.50641894]), array([28.95853645])], [array([41.03427157]), array([21.72341727])], [array([45.88788412]), array([22.73499421])], [array([39.92188139]), array([27.10313958])]]\n",
            "BEFORE BIASES: [[21.644129087103153, 23.424250383480523], [59.27213657603203, 16.212086332622103], [89.18197797957788, 35.85122194832088], [39.396819357865, 27.765651478285616]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgzt8ZFPKq1K"
      },
      "source": [
        "##Perception:\n",
        "        \n",
        "_\"begins the categorization process by calculating the similarity of the speaker output to each category’s stored word exemplars given their activations, in a variant of the Generalized Context Model (Nosofsky 1988). The overall similarities of the speaker output to each category are interpreted as a relative goodness of fit, and the speaker output is then stored as a new exemplar in the best fitting category.\"_\n",
        "\n",
        "- **Anti-ambiguity bias:** From Winter & Wedel (2016): _\"A final feature of the model is a bias against confusability of word perception, that is, an anti-ambiguity bias. The bias is implemented as follows: the probability of successful identification of an output with a word category is proportional to the degree to which the output uniquely maps to that category and to no other. In this way, distinctive speaker outputs are more likely to be stored than ambiguous outputs, with the result that distinctive phonetic values contribute more to the continuing evolution of the lexicon, both at the word and sound levels.\"_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LIhWa6ZYpEc"
      },
      "source": [
        "class Perception(Agent):\n",
        "\n",
        "  def similarity(self, signal, k=0.2):\n",
        "\n",
        "    # Calculate the activations first\n",
        "    targets = []\n",
        "    total_activations = []\n",
        "    for word_index in range(self.n_words):\n",
        "\n",
        "      # Only store exemplars until position 100\n",
        "      self.exemplars = self.lexicon[word_index][0][:101]\n",
        "\n",
        "      print(\"Exemplars beginning: \", self.exemplars)\n",
        "      activation_exemplars = []\n",
        "      j = 1\n",
        "      for exemplar in self.exemplars: \n",
        "        # activation = math.exp(0.2*j)\n",
        "        activation = 1/(0.2*j)\n",
        "        activation_exemplars.append(activation)\n",
        "        j += 1\n",
        "\n",
        "      total_activations.append(activation_exemplars)\n",
        "\n",
        "    similarities = []\n",
        "    word_index = 0\n",
        "    for word_index in range(self.n_words):\n",
        "      exemplar_sim = []\n",
        "      for dimension in range(self.n_dimensions):\n",
        "        index = 0\n",
        "        sum = 0\n",
        "        sum2 = 0\n",
        "        for exemplar in self.lexicon[word_index][0]:\n",
        "          sum += exemplar[dimension] * total_activations[word_index][index] * math.exp(-k * abs(signal[dimension]-exemplar[dimension]))\n",
        "          sum2 += total_activations[word_index][index] * math.exp(-k * abs(signal[dimension]-exemplar[dimension]))\n",
        "          index += 1\n",
        "        exemplar_sim.append(sum)\n",
        "\n",
        "      word_index += 1\n",
        "\n",
        "      similarities.append(exemplar_sim)\n",
        "      total_similarities = []\n",
        "      for word_cat in similarities:\n",
        "        sum = np.sum(word_cat)\n",
        "        total_similarities.append(sum)\n",
        "    print(similarities)\n",
        "    print(total_similarities)\n",
        "\n",
        "    max_similarity = max(total_similarities)\n",
        "    index_max_sim = total_similarities.index(max_similarity)\n",
        "    print(\"Signal most similar to word category: \", index_max_sim)\n",
        "\n",
        "    return self.add_anti_ambiguity_bias(index_max_sim, total_similarities, signal)\n",
        "\n",
        "  def add_anti_ambiguity_bias(self, index_max_sim, total_similarities, signal):\n",
        "\n",
        "    print(1/total_similarities[index_max_sim])\n",
        "    print(sum(total_similarities))\n",
        "    probability_storage = (total_similarities[index_max_sim])/sum(total_similarities)\n",
        "    print(probability_storage)\n",
        "\n",
        "    store = random.choices([True, False], weights = [probability_storage, 1-probability_storage], k = 1)\n",
        "    \n",
        "    if store[0]:\n",
        "      self.lexicon[index_max_sim][0].insert(0, signal)  \n",
        "\n",
        "    print(self.lexicon[index_max_sim])\n",
        "\n",
        "    return self.lexicon"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8vMEtV9QMbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "82c941ab-3371-46c1-8506-cc093adc8c47"
      },
      "source": [
        "test = Perception(4, 2).similarity([30, 40])"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Exemplars beginning:  [[9.75237658137242, 38.92905472886878], [16.266960948116612, 36.29869537030983], [18.471028284663927, 36.13215367783834], [9.948641000137656, 39.33042335349411], [9.319344398916082, 39.69840098485313], [8.987304140352737, 45.18876432309006], [12.457853352485284, 40.91155683984935], [9.33164817785287, 37.871048294335374], [13.33949733331133, 36.14058122042114], [5.736323210303294, 40.099509005458444], [12.754602667313009, 38.33505382610209], [13.95688639584677, 32.670418177933], [6.439071786931641, 40.5016319842337], [10.34988644221063, 41.67974427736982], [16.29672326199114, 41.74281792767967], [6.433395527751543, 40.37422444889608], [11.36299254061532, 33.77259613357665], [10.011821093331505, 39.299944614257356], [9.304115472617255, 40.17363650576549], [11.72163898209669, 37.1898512063813], [11.384021350707826, 31.90286961490613], [8.792146776392803, 39.79738954194651], [11.285540064988792, 41.25787814897235], [7.49536755814402, 39.44776228925373], [10.692878256819327, 30.781578162779546], [10.428165319229155, 34.08129561498756], [10.018685726962866, 37.73815824316022], [14.580402706916022, 37.585892108138154], [13.103881525156284, 35.32778360768729], [9.487991283278916, 39.5577639748247], [7.757652546529988, 38.515113165482994], [10.894151611917199, 38.11955487252647], [9.367121712570865, 38.160594743470156], [9.891851479215457, 38.97762670806013], [9.893352019676747, 30.04257897361512], [10.058735262395054, 39.563876544677015], [12.155383572015637, 42.153883576709504], [13.43363496392414, 35.23561565802671], [13.322108315491407, 40.30280655915125], [13.442037101695828, 34.887109235317084], [17.295972559351572, 39.24950001131628], [12.299408642521431, 40.69754021868581], [18.775582697087245, 37.667013884053254], [16.395819227937814, 40.435185440042105], [15.560333930153789, 32.72394439331826], [15.819226805750626, 36.34165415472931], [13.303914082563091, 42.91624582141656], [12.730949400595659, 41.82006031684752], [9.42287327225902, 39.3639085138468], [6.888714376356845, 37.13379594240359], [14.174723380510818, 34.936740933846714], [15.664123397601202, 40.51862385252713], [16.689406083935502, 38.45308246364797], [10.80591897072044, 36.683116211184156], [10.55134124613637, 41.29150996271364], [10.149153009894947, 40.777041335513786], [5.999587066831626, 39.162583890673304], [10.397879028675447, 32.08078890025175], [10.363982767964549, 38.30393060256057], [5.7407415791026155, 35.058324842363746], [8.047958013470563, 35.53040700425972], [13.51507373860122, 36.2150041591723], [10.13944691066426, 40.009836515435964], [9.289759314662264, 40.509649658484015], [5.976112675790932, 40.466012894145855], [12.236097231151872, 40.77134856408508], [9.071756078439543, 42.61886317875304], [12.663069592270665, 40.71833894009997], [15.490849107933474, 36.3050298413863], [18.526077727177853, 34.43287505536479], [10.63907457397449, 41.040818076413885], [10.866831656215352, 39.14650353657701], [12.118962475633971, 37.415799030697826], [11.969816518032559, 36.298398103621565], [13.44514948922734, 38.40732052928017], [10.06111863416496, 42.27792074548243], [9.9374860504162, 39.83372459189344], [10.17840139383695, 34.68951601783347], [13.49162278466121, 41.07864395492773], [15.452098343261788, 39.91242111953803], [10.206092826919814, 40.05749977278886], [8.452361478493156, 38.943222052906876], [9.612080150814528, 40.487918290193086], [13.306505202709461, 39.91826982209731], [7.702158255214258, 37.77885913093073], [17.232157962379297, 40.4871503566656], [6.645587633346527, 35.51930285159124], [13.313199674643803, 39.9460137798436], [5.086702249555741, 34.34789827841683], [15.212583233813639, 42.42680938527509], [10.397043392466244, 38.38141939381684], [9.715818377130416, 39.392207887785915], [11.160324960175078, 35.04396593509523], [9.39841070339488, 35.5125673287858], [13.773005182922155, 33.560663822267685], [10.82529953404693, 38.774270406860076], [16.438439727927463, 40.52290607013883], [9.305790402134521, 41.55915503146369], [10.684772928824554, 34.69824038072417], [8.773680795037452, 38.900934215505444]]\n",
            "Exemplars beginning:  [[26.84462080935342, 56.95061265377007], [24.808710765208634, 51.24884262806312], [25.819507162094336, 59.149800856639445], [20.614781065622164, 56.263620163983816], [27.14675410168504, 56.738136611634516], [26.958314002597596, 55.5403352482916], [25.146859701645376, 58.17146829171731], [22.589218486150315, 58.55399407570934], [23.606850470141726, 54.39599464959271], [25.035811728715736, 51.358150152957656], [26.306257833531692, 52.01579550529072], [27.6336252289407, 59.381434002400745], [22.879719324604583, 51.78252811057055], [27.560446438771613, 50.99006093196497], [23.789482940137763, 61.745113365972045], [27.90759798745789, 57.9566012168508], [29.08838119069155, 56.165192700237725], [23.284827662920552, 61.218871002733785], [26.52481330175715, 61.07167557039067], [19.24826725207379, 55.24961833002353], [30.153570403648253, 60.249069342503425], [23.424515135940617, 55.75012715733551], [16.496340778992817, 53.16031773592239], [29.988870088129914, 48.631332600132204], [26.96163438372009, 59.39212187489237], [24.236976963426397, 62.375173877229024], [20.737806277668078, 53.3962997400924], [21.515147638160727, 56.695131682928476], [22.752822378749443, 59.40450856088074], [23.60076456888151, 53.11288415385599], [23.1586721560654, 61.730999166813746], [25.1034433148062, 57.54974044878181], [21.384640701430595, 51.88553303950235], [24.84995067074027, 51.10767192204116], [27.445471971813067, 57.75472194774518], [26.82298928237891, 53.278640054789584], [22.931253167677816, 53.80977961276693], [21.732116168953084, 62.94981380534808], [18.865863075599, 52.821545319410575], [22.57472795086438, 55.51461751974715], [27.562350914688032, 59.126580858531526], [26.87676259980366, 55.737440271976055], [20.886781918306514, 52.03860484847452], [20.101277693946898, 57.69824346198585], [28.58627592640456, 58.74766381283075], [27.89242258587971, 58.35070030022681], [22.48798856809896, 51.976161331030205], [20.047160722287135, 58.081480459289736], [20.27775113183919, 62.52408990596753], [20.480387507961318, 54.723235809110285], [26.017180663747656, 57.334187217959006], [25.34300150827595, 56.48729671754763], [26.797855624172385, 61.38619985795083], [23.863063481463794, 57.79464225830195], [24.71122533736975, 54.253653721712595], [25.08006334277912, 50.43372293168686], [22.02138582382142, 53.61571279294003], [24.933342515520504, 59.15779697733926], [24.08778130484504, 53.714298256455066], [19.806004477486095, 56.499492462603534], [20.825838102039263, 51.888699563242874], [25.911351997441944, 50.61864739302542], [22.85611040933921, 54.81217607078062], [28.001291434033202, 56.87878944928278], [23.222225358367982, 57.54167687066886], [22.73702966879748, 57.383943593624956], [22.701170406544847, 55.56270045788983], [28.590513980148774, 58.16419074200563], [23.97809515549198, 50.40807029387443], [23.947605860402913, 54.96707189656637], [24.15471032072482, 58.46911989942481], [17.427610780578796, 57.730606155904205], [28.70169174408595, 55.27645950057478], [21.568556024435466, 57.384548408989076], [22.417831671888464, 52.887093875820625], [28.927618473181113, 55.06381680337198], [25.687276992697743, 53.86926898000806], [29.399837965792884, 54.17626086611497], [27.847306558896133, 57.93308167135836], [19.729211727363467, 53.6642293244747], [20.400103562695776, 60.46180118454336], [21.468656695064922, 57.995546838198955], [26.60314163813219, 50.9070161277899], [24.529599207071247, 57.410914983041856], [24.499648233922155, 53.621594074017594], [26.267330590160523, 59.65470832341419], [25.507230369677863, 59.18786392183012], [22.667833356822882, 61.71100902591926], [22.262353756166604, 54.87273256542087], [32.994146926918965, 60.63004375422521], [23.483263496154997, 55.39860901146884], [27.484048229686803, 57.63174890961231], [21.680345098108667, 58.08126729620879], [25.373281980877422, 63.407719720089105], [24.45574602939197, 53.9301909880649], [22.775219429167112, 60.04105281917917], [24.72076427984711, 57.82702668963191], [23.132057703298084, 56.55172981857455], [23.733041129513452, 59.025027920255354], [24.5159945867152, 63.73580067947072]]\n",
            "Exemplars beginning:  [[68.6896293662139, 1.8167198745628177], [68.62043084311108, 12.331440951258724], [67.73545528556006, 9.138061673028423], [71.03128667408565, 13.838824604289373], [72.92981223371036, 8.300702999619027], [62.93177421097736, 9.15267338626176], [70.19002572299502, 10.811084588855785], [78.33515681991855, 5.610643177825438], [79.2269838453628, 11.194612067600637], [66.0752447912977, 10.755903992386743], [72.47307382834319, 7.864920362520386], [75.17184295658402, 16.4916695201444], [69.46479205032551, 10.446188671230358], [76.57248321737273, 11.952036685961854], [69.60507965764323, 11.96691671157846], [76.53794724928834, 6.758903823684001], [73.99748185426864, 9.387251429903094], [71.43016172239035, 8.606047254335568], [63.92355069205423, 10.6013267757033], [71.9962407474014, 10.922180500760115], [70.90254860247948, 8.352338872329673], [70.93872246838848, 6.898553537957364], [71.60284258384473, 7.567999942796673], [70.16437986532212, 2.579137184029226], [73.02224002522902, 7.1424856442723295], [72.17873564782167, 9.72343930841451], [71.0366412766465, 10.965422136309881], [76.14557296297586, 5.391273156963825], [72.04041045933866, 7.2742632154819775], [71.54320229710605, 10.710489056528303], [71.55776450246603, 13.212990091593486], [66.38741548168973, 7.422126065930487], [67.8377391994591, 15.02919240582257], [70.06102899403751, 4.583186103844278], [70.94329802277443, 8.241637783675948], [70.6863496906406, 9.451865628436776], [69.9098505294146, 12.6129124881437], [69.7851577374803, 12.602925822188492], [69.38914442232382, 5.256435072420774], [64.61894352022571, 13.094822848619689], [72.15091285653244, 9.133683344963693], [79.60303277885018, 4.9198642486957445], [70.62697112217614, 5.024341420429832], [75.24854923902207, 9.189692179473898], [69.06502277791812, 10.193715123976796], [71.07498875882969, 11.02050703436371], [74.106727155931, 6.256048807777371], [72.4899906220476, 11.062202719301055], [66.0075995160932, 9.777472978991852], [69.56160351776586, 7.707858379489489], [68.57181452598371, 10.889980586317073], [72.85628672643419, 6.041779068611888], [70.85866223771573, 7.838247463937883], [73.30179871115777, 5.6540319527284675], [68.55276483334727, 7.48241471550493], [69.72798563716682, 10.819098300966012], [73.2937972973879, 12.03564296822977], [71.0800213330759, 7.511271169257819], [69.99515406014906, 13.868576020779557], [69.46505776952968, 10.70264252670755], [76.14339391342085, 10.620188354220229], [64.57204730908275, 10.933643047565266], [69.1893677623877, 14.472812722869172], [68.54861396036938, 4.378973918209965], [71.77876020610042, 16.22144398314203], [67.69285032824563, 12.014839896408281], [73.21435182754094, 9.880710673709993], [68.70498563590941, 13.176598323967772], [66.45101824919526, 12.28932320844705], [70.10820025912962, 10.198682304624755], [73.24271247526903, 7.403156708909426], [69.45517093616864, 11.337445006562868], [63.49256111199479, 8.708025223493664], [68.60650080091924, 7.014115485243549], [68.44902509255436, 13.050137422933746], [69.75829153161226, 11.308117768856272], [68.98869337803647, 12.02854072438069], [72.03404938597893, 11.885325726672495], [67.2636415634112, 11.843584673822539], [76.33232702319673, 12.3161267862353], [71.87203285564624, 8.220037509454139], [68.85185084805538, 10.910898808172435], [75.45354015794632, 15.22414254514782], [71.91039317678748, 15.66886075432361], [74.36907701305235, 12.163225333380751], [72.83183314770298, 7.66395656757957], [68.25303937393878, 13.035821403441748], [70.90919812975743, 14.06644433791135], [66.66189719866264, 10.155279308360303], [70.50772764321623, 10.786679097743237], [70.91115452606057, 9.47658440830214], [61.72916690669408, 6.525137681907795], [72.38013334488872, 5.621444373990439], [72.16169649069313, 9.540981529223071], [68.84884188663128, 7.122757925052347], [68.58901990603236, 12.820503717624952], [69.09220723450352, 9.44169020541416], [71.81895929085478, 14.445874973022498], [72.23270485161613, 19.720587393693755], [70.92742591900308, 7.816560894188024]]\n",
            "Exemplars beginning:  [[74.30641724708606, 45.59527509291557], [82.8644473766401, 44.49047243725831], [72.75909466861002, 41.981419564903895], [77.42150069258335, 49.97227199369591], [76.49977051142238, 47.43665035247618], [72.85597368952361, 44.03526978629565], [74.89566216608031, 40.730736194554964], [77.02868756465554, 44.63140204896431], [77.9996139540201, 45.31843129425146], [79.64984428261971, 45.25495123588227], [80.33240325531135, 42.5097703810132], [80.39764768334447, 46.81635575923309], [77.10873911978193, 46.067916194747305], [78.76069063382432, 45.49582267602912], [79.41543893104483, 42.74008599593338], [80.68558700267687, 47.585738589493204], [76.40237301598451, 47.15787422998258], [78.61951597038751, 51.903816641149604], [69.83360770797958, 51.91229224192471], [77.78137046440399, 43.4673978062714], [75.80567867287571, 48.562214022185145], [76.6952870753963, 49.898804925142315], [77.83258503764594, 40.27462237002446], [87.84661961197428, 44.73059615518934], [81.6521831795113, 45.04380079382179], [80.33528705046758, 48.32177849872607], [81.67680565939334, 44.21390086700802], [80.36492381639081, 46.24885370892721], [80.41963381269115, 44.66960334694009], [76.85115879727371, 49.32182414424671], [86.99418406970067, 45.406084141216084], [81.30843357415017, 43.06320027040582], [79.24454255664101, 47.5607628342392], [77.33021876775386, 48.57241657211572], [77.80535163357266, 42.50201935056048], [80.49824619173135, 44.387769662948976], [82.34175339182815, 46.000899738552036], [73.03146444043804, 48.81129896883742], [77.456457771884, 43.6488364183179], [75.8193968139056, 45.39087932431793], [78.48311816705213, 46.729231021650605], [76.12692561430936, 48.0351704642011], [83.56447323141677, 40.51536012513821], [82.4360552738014, 47.69824394444254], [75.77958502112016, 49.149204577637086], [76.64594080866023, 44.97568503502883], [77.7001442054331, 44.539940531909785], [79.7152306590473, 45.49869609647468], [80.82954434575979, 42.25034871411358], [77.30279194374141, 40.69243683320387], [80.5378868062525, 46.15360772596692], [82.95968505254467, 45.53859793540112], [76.84976278343134, 48.0508088252684], [75.53398825262256, 42.95311050350703], [78.71903823019116, 43.806849002253514], [82.65101027210385, 43.774288038643874], [78.2430022181146, 45.8056785266797], [82.2656552031747, 44.225287587050595], [76.08291884427616, 47.7355582128021], [74.76845283663901, 43.82821534366729], [78.07771788837223, 53.16311483502446], [79.69723002404605, 43.918345018142546], [79.58717670695096, 46.749683152378566], [79.4947033111828, 50.37626039035657], [78.65290337847556, 42.81579436208915], [79.43277726529125, 38.34802187061632], [78.09156062486565, 43.70095741080631], [80.68099075610502, 46.934054571017946], [78.31735342482563, 41.23397324775073], [84.96320904727654, 44.08021862098202], [73.82222214240034, 48.32992222547123], [80.52905864851326, 47.60143914972282], [82.87441578901017, 44.839465711121235], [74.95038060624486, 42.770686217408034], [81.24923256299678, 45.60395766258352], [73.68623555523871, 45.28404304480552], [80.35589139838756, 44.46607475436587], [74.2789543997548, 43.338968571235654], [78.11026468948224, 48.81464329345293], [78.53034021594682, 43.76836994835691], [77.13220384239261, 46.9144065286685], [71.48176920018321, 50.79785831038914], [80.21052045879516, 44.45337131329373], [79.61566643240273, 42.53397819729458], [73.97217632372649, 47.56543077722192], [76.63096415990532, 43.94446739346498], [79.36234546562103, 42.293303386345634], [77.88241560420462, 48.470562551614684], [79.17222443211651, 46.339384287141705], [74.59948508693492, 43.29432646780148], [79.6486898055789, 46.093945733797035], [80.36904613142697, 45.38825747113683], [79.96361488888212, 46.0460602062941], [80.68520847919794, 46.01507789568344], [79.846591864583, 43.429536208281114], [83.25797439030214, 46.135471494409174], [80.14491523390747, 46.24444842163729], [80.97853176433475, 40.51225637956241], [77.58730322144466, 43.70756595096599], [75.60144443569126, 41.25199402562967]]\n",
            "[[11.866226523915232, 680.7246523383477], [279.4348147737336, 68.37120128995274], [0.69316002821522, 0.7295382438818149], [0.1832023718917412, 438.3697867982698]]\n",
            "[692.5908788622629, 347.80601606368634, 1.422698272097035, 438.55298917016154]\n",
            "Signal most similar to word category:  0\n",
            "0.0014438538400082977\n",
            "1480.3725823682078\n",
            "0.4678490314609172\n",
            "False\n",
            "[[[9.75237658137242, 38.92905472886878], [16.266960948116612, 36.29869537030983], [18.471028284663927, 36.13215367783834], [9.948641000137656, 39.33042335349411], [9.319344398916082, 39.69840098485313], [8.987304140352737, 45.18876432309006], [12.457853352485284, 40.91155683984935], [9.33164817785287, 37.871048294335374], [13.33949733331133, 36.14058122042114], [5.736323210303294, 40.099509005458444], [12.754602667313009, 38.33505382610209], [13.95688639584677, 32.670418177933], [6.439071786931641, 40.5016319842337], [10.34988644221063, 41.67974427736982], [16.29672326199114, 41.74281792767967], [6.433395527751543, 40.37422444889608], [11.36299254061532, 33.77259613357665], [10.011821093331505, 39.299944614257356], [9.304115472617255, 40.17363650576549], [11.72163898209669, 37.1898512063813], [11.384021350707826, 31.90286961490613], [8.792146776392803, 39.79738954194651], [11.285540064988792, 41.25787814897235], [7.49536755814402, 39.44776228925373], [10.692878256819327, 30.781578162779546], [10.428165319229155, 34.08129561498756], [10.018685726962866, 37.73815824316022], [14.580402706916022, 37.585892108138154], [13.103881525156284, 35.32778360768729], [9.487991283278916, 39.5577639748247], [7.757652546529988, 38.515113165482994], [10.894151611917199, 38.11955487252647], [9.367121712570865, 38.160594743470156], [9.891851479215457, 38.97762670806013], [9.893352019676747, 30.04257897361512], [10.058735262395054, 39.563876544677015], [12.155383572015637, 42.153883576709504], [13.43363496392414, 35.23561565802671], [13.322108315491407, 40.30280655915125], [13.442037101695828, 34.887109235317084], [17.295972559351572, 39.24950001131628], [12.299408642521431, 40.69754021868581], [18.775582697087245, 37.667013884053254], [16.395819227937814, 40.435185440042105], [15.560333930153789, 32.72394439331826], [15.819226805750626, 36.34165415472931], [13.303914082563091, 42.91624582141656], [12.730949400595659, 41.82006031684752], [9.42287327225902, 39.3639085138468], [6.888714376356845, 37.13379594240359], [14.174723380510818, 34.936740933846714], [15.664123397601202, 40.51862385252713], [16.689406083935502, 38.45308246364797], [10.80591897072044, 36.683116211184156], [10.55134124613637, 41.29150996271364], [10.149153009894947, 40.777041335513786], [5.999587066831626, 39.162583890673304], [10.397879028675447, 32.08078890025175], [10.363982767964549, 38.30393060256057], [5.7407415791026155, 35.058324842363746], [8.047958013470563, 35.53040700425972], [13.51507373860122, 36.2150041591723], [10.13944691066426, 40.009836515435964], [9.289759314662264, 40.509649658484015], [5.976112675790932, 40.466012894145855], [12.236097231151872, 40.77134856408508], [9.071756078439543, 42.61886317875304], [12.663069592270665, 40.71833894009997], [15.490849107933474, 36.3050298413863], [18.526077727177853, 34.43287505536479], [10.63907457397449, 41.040818076413885], [10.866831656215352, 39.14650353657701], [12.118962475633971, 37.415799030697826], [11.969816518032559, 36.298398103621565], [13.44514948922734, 38.40732052928017], [10.06111863416496, 42.27792074548243], [9.9374860504162, 39.83372459189344], [10.17840139383695, 34.68951601783347], [13.49162278466121, 41.07864395492773], [15.452098343261788, 39.91242111953803], [10.206092826919814, 40.05749977278886], [8.452361478493156, 38.943222052906876], [9.612080150814528, 40.487918290193086], [13.306505202709461, 39.91826982209731], [7.702158255214258, 37.77885913093073], [17.232157962379297, 40.4871503566656], [6.645587633346527, 35.51930285159124], [13.313199674643803, 39.9460137798436], [5.086702249555741, 34.34789827841683], [15.212583233813639, 42.42680938527509], [10.397043392466244, 38.38141939381684], [9.715818377130416, 39.392207887785915], [11.160324960175078, 35.04396593509523], [9.39841070339488, 35.5125673287858], [13.773005182922155, 33.560663822267685], [10.82529953404693, 38.774270406860076], [16.438439727927463, 40.52290607013883], [9.305790402134521, 41.55915503146369], [10.684772928824554, 34.69824038072417], [8.773680795037452, 38.900934215505444]], 'C']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}